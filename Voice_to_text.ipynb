{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9arcurvMbDfz",
        "outputId": "0a0224bf-aa83-410d-a5b5-38dcba8506fe"
      },
      "outputs": [],
      "source": [
        "!apt update \n",
        "!apt install ffmpeg\n",
        "\n",
        "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116\n",
        "!pip install git+https://github.com/openai/whisper.git \n",
        "!pip install diffusers==0.2.4\n",
        "!pip install transformers scipy ftfy\n",
        "!pip install \"ipywidgets>=7,<8\" \n",
        "\n",
        "import whisper\n",
        "import cv2\n",
        "\n",
        "# loading model\n",
        "model = whisper.load_model('small')\n",
        "\n",
        "# loading audio file\n",
        "audio = whisper.load_audio('prompt.m4a')\n",
        "# padding audio to 30 seconds\n",
        "audio = whisper.pad_or_trim(audio)\n",
        "\n",
        "# generating spectrogram\n",
        "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "# decoding\n",
        "options = whisper.DecodingOptions()\n",
        "result = whisper.decode(model, mel, options)\n",
        "\n",
        "# ready prompt!\n",
        "prompt = result.text\n",
        "\n",
        "# adding tips\n",
        "prompt += 'Try to draw what you see in the picture'\n",
        "print(prompt)\n",
        "\n",
        "# generate the image corresponding to the prompt\n",
        "img_path = \"images/\" + prompt + \".jpg\"\n",
        "img = cv2.imread(img_path)\n",
        "cv2.imshow(\"Image Prompt\", img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# provide positive feedback to the child\n",
        "print(\"Great job! You did it!\")\n",
        "\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    'CompVis/stable-diffusion-v1-4',\n",
        "    revision='fp16',\n",
        "    torcj_dtype=torch.float16,\n",
        "    use_auth_token=True\n",
        ")\n",
        "\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "with torch.autocast('cuda'):\n",
        "    image = pipe(prompt)['sample'][0]\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.title(prompt)\n",
        "plt.axis('off')\n",
        "plt.savefig('result.jpg')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPBix0yjcXNe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
